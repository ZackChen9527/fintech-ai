package com.codinghappy.fintechai.module.crawler.controller;

import com.codinghappy.fintechai.module.crawler.dto.CompanyProfileDTO;
import com.codinghappy.fintechai.module.crawler.service.CrawlerService;
import com.codinghappy.fintechai.module.crawler.task.LinkedInCrawlerTask;
import com.codinghappy.fintechai.repository.CompanyRepository;
import com.codinghappy.fintechai.repository.entity.CompanyEntity;
// æ–°å¢å¯¼å…¥
import com.codinghappy.fintechai.module.analysis.task.AnalysisTask;

import jakarta.validation.constraints.NotBlank;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

import java.util.List;
import java.util.stream.Collectors;

@Slf4j
@RestController
@RequestMapping("/crawler")
@RequiredArgsConstructor
public class CrawlerController {

    // æ³¨å…¥æ¥å£
    private final CrawlerService crawlerService;

    // 1. åœ¨ Controller ä¸­æ³¨å…¥ Repository
    private final CompanyRepository companyRepository;

    // 2. âœ… æ–°å¢æ³¨å…¥ï¼šåˆ†æä»»åŠ¡ (å°é’æœºå¼€å…³)
    private final AnalysisTask analysisTask;

    private final LinkedInCrawlerTask linkedinCrawlerTask;

    @PostMapping("/linkedin/single")
    public ResponseEntity<CompanyProfileDTO> crawlLinkedInCompany(
            @RequestParam @NotBlank String linkedinUrl) {
        try {
            CompanyProfileDTO result = crawlerService.crawlCompany(linkedinUrl);
            return ResponseEntity.ok(result);
        } catch (Exception e) {
            log.error("æŠ“å–LinkedInå…¬å¸å¤±è´¥: {}", linkedinUrl, e);
            return ResponseEntity.internalServerError().build();
        }
    }

    @PostMapping("/linkedin/batch")
    public ResponseEntity<List<CompanyProfileDTO>> batchCrawlLinkedIn(
            @RequestBody List<String> linkedinUrls) {
        try {
            List<CompanyProfileDTO> results = crawlerService.batchCrawl(linkedinUrls);
            return ResponseEntity.ok(results);
        } catch (Exception e) {
            log.error("æ‰¹é‡æŠ“å–å¤±è´¥", e);
            return ResponseEntity.internalServerError().build();
        }
    }

    /**
     * æ ¸å¿ƒæ¥å£ï¼šæœç´¢ -> æŠ“å– -> å…¥åº“ -> ã€è‡ªåŠ¨è§¦å‘åˆ†æã€‘
     */
    @GetMapping("/linkedin/search")
    public ResponseEntity<List<CompanyProfileDTO>> searchCompanies(
            @RequestParam @NotBlank String keyword,
            @RequestParam(defaultValue = "10") int limit) {
        try {
            log.info("ğŸ” æ¥åˆ°æœç´¢æŒ‡ä»¤: {}, é™åˆ¶: {}", keyword, limit);

            // 1. æŠ“å–æ•°æ® (è¿™é‡Œè°ƒç”¨ Serper API)
            List<CompanyProfileDTO> results = crawlerService.searchCompanies(keyword, limit);

            if (results.isEmpty()) {
                log.warn("æœªæœç´¢åˆ°ä»»ä½•å…¬å¸æ•°æ®");
                return ResponseEntity.ok(results);
            }

            // 2. å°† DTO è½¬æ¢ä¸º Entity
            List<CompanyEntity> companies = results.stream().map(dto -> {
                CompanyEntity entity = new CompanyEntity();
                entity.setName(dto.getCompanyName());
                entity.setDescription(dto.getDescription());
                entity.setLinkedinUrl(dto.getLinkedinUrl());
                entity.setDataSource("LinkedIn_Search"); // æ ‡è®°æ¥æº
                entity.setIsActive(true);
                // è¿™é‡Œå¯ä»¥è¡¥å…… website ç­‰å…¶ä»–å­—æ®µçš„æ˜ å°„
                return entity;
            }).collect(Collectors.toList());

            // 3. å­˜å…¥ MySQL (åŸææ–™å…¥åº“)
            companyRepository.saveAll(companies);
            log.info("âœ… å·²æˆåŠŸå…¥åº“ {} å®¶å…¬å¸", companies.size());

            // 4. ğŸ”¥ã€æ ¸å¿ƒè”åŠ¨ã€‘ç«‹å³è§¦å‘ AI åˆ†æä»»åŠ¡
            log.info("ğŸš€ è§¦å‘ DeepSeek æ‰¹é‡åˆ†æ...");
            analysisTask.executeBatchAnalysis();

            return ResponseEntity.ok(results);

        } catch (Exception e) {
            log.error("æœç´¢å¹¶åˆ†ææµç¨‹å¤±è´¥: {}", keyword, e);
            return ResponseEntity.internalServerError().build();
        }
    }

    /**
     * ğŸ’° èµšé’±æ¥å£ï¼šå®¢æˆ·ç»™ä½  Excel/åå•ï¼Œä½ æŠŠ URL åˆ—è¡¨ä¼ è¿›æ¥ï¼Œç³»ç»Ÿè‡ªåŠ¨å‡ºåˆ†æã€‚
     * * ç”¨æ³•ï¼š
     * POST /crawler/linkedin/batch-analyze
     * Body: ["https://www.linkedin.com/company/stripe", "https://www.linkedin.com/company/adyen"]
     */
    @PostMapping("/linkedin/batch-analyze")
    public ResponseEntity<String> batchAnalyzeUrls(@RequestBody List<String> linkedinUrls) {
        log.info("ğŸ’° æ”¶åˆ°å®¢æˆ·æä¾›çš„åå•ï¼Œå…± {} ä¸ªç›®æ ‡", linkedinUrls.size());

        // 1. å¯åŠ¨æ‰¹é‡æŠ“å– (LinkedInCrawlerTask å·²ç»å…·å¤‡å»é‡å’Œå…¥åº“åŠŸèƒ½)
        // æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨çš„æ˜¯ task çš„ executeBatchCrawlï¼Œå®ƒä¼šå­˜åº“
        var crawlResult = linkedinCrawlerTask.executeBatchCrawl(linkedinUrls);

        log.info("âœ… åå•æŠ“å–å…¥åº“å®Œæˆï¼ŒæˆåŠŸ: {}, å¤±è´¥: {}ã€‚å³å°†å¼€å§‹æ·±åº¦åˆ†æ...",
                crawlResult.getSuccessCount(), crawlResult.getFailureCount());

        // 2. ç«‹å³è§¦å‘ DeepSeek åˆ†æ (åˆ†æåˆšæ‰å…¥åº“çš„é‚£äº›)
        analysisTask.executeBatchAnalysis();

        return ResponseEntity.ok(String.format(
                "è®¢å•å·²æ¥æ”¶ï¼\næˆåŠŸæŠ“å–: %d å®¶\nç³»ç»Ÿæ­£åœ¨åå°è¿›è¡Œ DeepSeek æ·±åº¦åˆ†æã€‚\nè¯· 2 åˆ†é’Ÿåè®¿é—® /api/export/pdf/latest ä¸‹è½½æŠ¥å‘Šå‘ç»™å®¢æˆ·ã€‚",
                crawlResult.getSuccessCount()
        ));
    }

    @GetMapping("/health")
    public ResponseEntity<String> health() {
        return ResponseEntity.ok("Crawler service is healthy");
    }
}